# ============================================
# Enterprise RAG System - Environment Variables
# ============================================
# Copy this file to .env and fill in your values

# --------------------------------------------
# LLM Configuration
# --------------------------------------------
# OpenAI (default)
OPENAI_API_KEY=your-openai-api-key
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.0
LLM_MAX_TOKENS=2048

# Anthropic (optional)
ANTHROPIC_API_KEY=your-anthropic-api-key
# LLM_PROVIDER=anthropic
# LLM_MODEL=claude-3-haiku-20240307

# Groq (optional)
GROQ_API_KEY=your-groq-api-key
# LLM_PROVIDER=groq
# LLM_MODEL=llama-3.1-8b-instant

# --------------------------------------------
# Embedding Configuration
# --------------------------------------------
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=text-embedding-3-small
# EMBEDDING_PROVIDER=sentence_transformers
# EMBEDDING_MODEL=all-MiniLM-L6-v2

# Cohere (optional)
COHERE_API_KEY=your-cohere-api-key
# EMBEDDING_PROVIDER=cohere
# EMBEDDING_MODEL=embed-english-v3.0

# --------------------------------------------
# Vector Store Configuration
# --------------------------------------------
VECTOR_STORE_TYPE=chroma
CHROMA_PERSIST_DIR=./data/chroma
CHROMA_COLLECTION_NAME=rag_collection

# Pinecone (optional)
PINECONE_API_KEY=your-pinecone-api-key
PINECONE_ENVIRONMENT=your-environment
PINECONE_INDEX_NAME=your-index
# VECTOR_STORE_TYPE=pinecone

# --------------------------------------------
# Retrieval Configuration
# --------------------------------------------
RETRIEVAL_TOP_K=10
USE_MMR=true
MMR_K=5
MMR_LAMBDA=0.5
HYBRID_ALPHA=0.7

# Reranking
RERANKER_TYPE=cross_encoder
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
# RERANKER_TYPE=cohere
# RERANKER_MODEL=rerank-english-v2.0

# Compression
USE_COMPRESSION=true
COMPRESSION_MODEL=gpt-4o-mini

# --------------------------------------------
# Chunking Configuration
# --------------------------------------------
CHUNK_STRATEGY=recursive
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
# CHUNK_STRATEGY=semantic
# SEMANTIC_THRESHOLD=0.75

# --------------------------------------------
# Query Processing
# --------------------------------------------
ENABLE_QUERY_REWRITING=true
ENABLE_MULTI_QUERY=false
MULTI_QUERY_COUNT=3
ENABLE_HYDE=false

# --------------------------------------------
# Generation Configuration
# --------------------------------------------
INCLUDE_CITATIONS=true
CITATION_STYLE=numbered
MAX_CONTEXT_DOCS=5
CONTEXT_WINDOW_SIZE=4000

# --------------------------------------------
# Guardrails Configuration
# --------------------------------------------
ENABLE_INPUT_GUARDRAILS=true
ENABLE_OUTPUT_GUARDRAILS=true
ENABLE_PII_FILTER=true
ENABLE_HALLUCINATION_CHECK=false
MAX_QUERY_LENGTH=1000
BLOCKED_TOPICS=

# --------------------------------------------
# Memory Configuration
# --------------------------------------------
MEMORY_TYPE=buffer
MEMORY_WINDOW_SIZE=10
# MEMORY_TYPE=summary
# SUMMARY_THRESHOLD=8

# --------------------------------------------
# Agent Configuration
# --------------------------------------------
AGENT_MAX_ITERATIONS=3
AGENT_RELEVANCE_THRESHOLD=0.5

# --------------------------------------------
# API Configuration
# --------------------------------------------
API_HOST=0.0.0.0
API_PORT=8000
API_CORS_ORIGINS=["http://localhost:3000"]
API_RATE_LIMIT=100
ENABLE_STREAMING=true

# --------------------------------------------
# Evaluation Configuration
# --------------------------------------------
EVALUATION_MODEL=gpt-4o-mini
ENABLE_RAGAS=true

# --------------------------------------------
# Logging Configuration
# --------------------------------------------
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# --------------------------------------------
# LangSmith (optional - for tracing)
# --------------------------------------------
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=your-langsmith-api-key
LANGCHAIN_PROJECT=enterprise-rag
